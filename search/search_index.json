{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"DuckSearch <p>Efficient BM25 with DuckDB \ud83e\udd86</p> <p></p> <p> DuckSearch is a lightweight and easy-to-use library to search documents. DuckSearch is built on top of DuckDB, a high-performance analytical database. DuckDB is designed to execute analytical SQL queries fast, and DuckSearch leverages this to provide efficient search and filtering features. DuckSearch index can be updated with new documents and documents can be deleted as well. DuckSearch also supports HuggingFace datasets, allowing to index datasets directly from the HuggingFace Hub. </p>"},{"location":"#installation","title":"Installation","text":"<p>Install DuckSearch using pip:</p> <pre><code>pip install ducksearch\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>The complete documentation is available here, which includes in-depth guides, examples, and API references.</p>"},{"location":"#upload","title":"Upload","text":"<p>We can upload documents to DuckDB using the <code>upload.documents</code> function. The documents are stored in a DuckDB database, and the <code>fields</code> are indexed with BM25.</p> <pre><code>from ducksearch import upload\n\ndocuments = [\n    {\n        \"id\": 0,\n        \"title\": \"Hotel California\",\n        \"style\": \"rock\",\n        \"date\": \"1977-02-22\",\n        \"popularity\": 9,\n    },\n    {\n        \"id\": 1,\n        \"title\": \"Here Comes the Sun\",\n        \"style\": \"rock\",\n        \"date\": \"1969-06-10\",\n        \"popularity\": 10,\n    },\n    {\n        \"id\": 2,\n        \"title\": \"Alive\",\n        \"style\": \"electro, punk\",\n        \"date\": \"2007-11-19\",\n        \"popularity\": 9,\n    },\n]\n\nupload.documents(\n    database=\"ducksearch.duckdb\",\n    key=\"id\", # unique document identifier\n    fields=[\"title\", \"style\", \"date\", \"popularity\"], # list of fields to index\n    documents=documents,\n    dtypes={\n        \"date\": \"DATE\",\n        \"popularity\": \"INT\",\n    },\n)\n</code></pre>"},{"location":"#search","title":"Search","text":"<p><code>search.documents</code> returns a list of list of documents ordered by relevance. We can control the number of documents to return using the <code>top_k</code> parameter. The following example demonstrates how to search for documents with the queries \"punk\" and \"california\" while filtering the results to include only documents with a date after 1970 and a popularity score greater than 8.</p> <pre><code>from ducksearch import search\n\nsearch.documents(\n    database=\"ducksearch.duckdb\",\n    queries=[\"punk\", \"california\"],\n    top_k=10,\n    filters=\"YEAR(date) &gt;= 1970 AND popularity &gt; 8\",\n)\n</code></pre> <pre><code>[\n    [\n        {\n            \"id\": \"2\",\n            \"title\": \"Alive\",\n            \"style\": \"electro, punk\",\n            \"date\": Timestamp(\"2007-11-19 00:00:00\"),\n            \"popularity\": 9,\n            \"score\": 0.17841622233390808,\n        }\n    ],\n    [\n        {\n            \"id\": \"0\",\n            \"title\": \"Hotel California\",\n            \"style\": \"rock, pop\",\n            \"date\": Timestamp(\"1977-02-22 00:00:00\"),\n            \"popularity\": 9,\n            \"score\": 0.156318798661232,\n        }\n    ],\n]\n</code></pre> <p>Filters are SQL expressions that are applied to the search results. We can use every filtering function DuckDB provides such as date functions.</p>"},{"location":"#delete-and-update-index","title":"Delete and update index","text":"<p>We can delete documents and update the BM25 weights accordingly using the <code>delete.documents</code> function.</p> <pre><code>from ducksearch import delete\n\ndelete.documents(\n    database=\"ducksearch.duckdb\",\n    ids=[0, 1],\n)\n</code></pre> <p>To update the index, we should first delete the documents and then upload the updated documents.</p>"},{"location":"#extra-features","title":"Extra features","text":""},{"location":"#huggingface","title":"HuggingFace","text":"<p>The <code>upload.documents</code> function can also index HuggingFace datasets directly from the url.  The following example demonstrates how to index the FineWeb dataset from HuggingFace:</p> <pre><code>from ducksearch import upload\n\nupload.documents(\n    database=\"fineweb.duckdb\",\n    key=\"id\",\n    fields=[\"text\", \"url\", \"date\", \"language\", \"token_count\", \"language_score\"],\n    documents=\"https://huggingface.co/datasets/HuggingFaceFW/fineweb/resolve/main/sample/10BT/000_00000.parquet\",\n    dtypes={\n        \"date\": \"DATE\",\n        \"token_count\": \"INT\",\n        \"language_score\": \"FLOAT\",\n    },\n    limit=1000, # demonstrate with a small dataset\n)\n</code></pre> <p>We can then search the FineWeb dataset with the <code>search.documents</code> function:</p> <pre><code>from ducksearch import search\n\nsearch.documents(\n    database=\"fineweb.duckdb\",\n    queries=\"earth science\",\n    top_k=2,\n)\n</code></pre> <pre><code>[\n    {\n        \"id\": \"&lt;urn:uuid:1e6ae53b-e0d7-431b-8d46-290244e597e9&gt;\",\n        \"text\": \"Earth Science Tutors in Rowland ...\",\n        \"date\": Timestamp(\"2017-08-19 00:00:00\"),\n        \"language\": \"en\",\n        \"token_count\": 313,\n        \"language_score\": 0.8718525171279907,\n        \"score\": 1.1588547229766846,\n    },\n    {\n        \"score\": 1.6727683544158936,\n        \"id\": \"&lt;urn:uuid:c732ce90-2fbf-41ad-8916-345f6c08e452&gt;\",\n        \"text\": \"The existing atmosphere surrounding the earth contains ...\",\n        \"url\": \"http://www.accuracyingenesis.com/atmargon.html\",\n        \"date\": Timestamp(\"2015-04-02 00:00:00\"),\n        \"language\": \"en\",\n        \"token_count\": 1348,\n        \"language_score\": 0.9564403295516968,\n    },\n]\n</code></pre>"},{"location":"#benchmark","title":"Benchmark","text":"Dataset ndcg@10 hits@1 hits@10 mrr@10 map@10 r-precision qps Indexation Time (s) Number of Documents and Queries arguana 0.3779 0.0 0.8267 0.2491 0.2528 0.0108 117.80 1.42 1,406 queries, 8.67K documents climate-fever 0.1184 0.1068 0.3648 0.1644 0.0803 0.0758 5.88 302.39 1,535 queries, 5.42M documents dbpedia-entity 0.6046 0.7669 5.6241 0.8311 0.0649 0.0741 113.20 181.42 400 queries, 4.63M documents fever 0.3861 0.2583 0.5826 0.3525 0.3329 0.2497 74.40 329.70 6,666 queries, 5.42M documents fiqa 0.2445 0.2207 0.6790 0.3002 0.1848 0.1594 545.77 6.04 648 queries, 57K documents hotpotqa 0.4487 0.5059 0.9699 0.5846 0.3642 0.3388 48.15 163.14 7,405 queries, 5.23M documents msmarco 0.8951 1.0 8.6279 1.0 0.0459 0.0473 35.11 202.37 6,980 queries, 8.84M documents nfcorpus 0.3301 0.4396 2.4087 0.5292 0.1233 0.1383 3464.66 0.99 323 queries, 3.6K documents nq 0.2451 0.1272 0.4574 0.2099 0.1934 0.1240 150.23 71.43 3,452 queries, 2.68M documents quora 0.7705 0.6783 1.1749 0.7606 0.7206 0.6502 741.13 3.78 10,000 queries, 523K documents scidocs 0.1025 0.1790 0.8240 0.2754 0.0154 0.0275 879.11 4.46 1,000 queries, 25K documents scifact 0.6908 0.5533 0.9133 0.6527 0.6416 0.5468 2153.64 1.22 300 queries, 5K documents trec-covid 0.9533 1.0 9.4800 1.0 0.0074 0.0077 112.38 22.15 50 queries, 171K documents webis-touche2020 0.4130 0.5510 3.7347 0.7114 0.0564 0.0827 104.65 44.14 49 queries, 382K documents"},{"location":"#references","title":"References","text":"<ul> <li> <p>DuckDB</p> </li> <li> <p>DuckDB Full Text Search: Note that DuckSearch rely partially on the DuckDB Full Text Search extension but accelerate the search process via <code>top_k_token</code> approximation, pre-computation of scores and multi-threading.</p> </li> </ul>"},{"location":"#license","title":"License","text":"<p>DuckSearch is released under the MIT license.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@misc{PyLate,\n  title={DuckSearch, efficient search with DuckDB},\n  author={Sourty, Raphael},\n  url={https://github.com/lightonai/ducksearch},\n  year={2024}\n}\n</code></pre>"},{"location":"api/overview/","title":"Overview","text":""},{"location":"api/overview/#decorators","title":"decorators","text":"<ul> <li>connect_to_duckdb</li> <li>execute_with_duckdb</li> </ul>"},{"location":"api/overview/#evaluation","title":"evaluation","text":"<ul> <li>evaluate</li> <li>load_beir</li> </ul>"},{"location":"api/overview/#hf","title":"hf","text":"<ul> <li>insert_documents</li> </ul>"},{"location":"api/overview/#search","title":"search","text":"<ul> <li>documents</li> <li>graphs</li> <li>queries</li> <li>search</li> <li>update_index_documents</li> <li>update_index_queries</li> </ul>"},{"location":"api/overview/#tables","title":"tables","text":"<ul> <li>create_documents</li> <li>create_documents_queries</li> <li>create_queries</li> <li>create_schema</li> <li>insert_documents</li> <li>insert_documents_queries</li> <li>insert_queries</li> <li>select_documents</li> <li>select_documents_columns</li> <li>select_queries</li> </ul>"},{"location":"api/overview/#upload","title":"upload","text":"<ul> <li>documents</li> <li>queries</li> </ul>"},{"location":"api/overview/#utils","title":"utils","text":"<ul> <li>batchify</li> <li>plot</li> </ul>"},{"location":"api/decorators/connect-to-duckdb/","title":"connect_to_duckdb","text":"<p>Establish a connection to the DuckDB database.</p>"},{"location":"api/decorators/connect-to-duckdb/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name or path of the DuckDB database to connect to.</p> </li> <li> <p>read_only (bool) \u2013 defaults to <code>False</code></p> <p>Whether to open the database in read-only mode. Default is False.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration settings for the DuckDB connection.</p> </li> </ul>"},{"location":"api/decorators/execute-with-duckdb/","title":"execute_with_duckdb","text":"<p>Decorator to execute a SQL query using DuckDB.</p>"},{"location":"api/decorators/execute-with-duckdb/#parameters","title":"Parameters","text":"<ul> <li> <p>relative_path (str | list[str])</p> <p>A string or list of strings specifying the path(s) to the SQL file(s).</p> </li> <li> <p>read_only (bool) \u2013 defaults to <code>False</code></p> <p>Whether the DuckDB connection should be read-only. Default is False.</p> </li> <li> <p>fields (list[str] | None) \u2013 defaults to <code>None</code></p> <p>A list of fields to use as keys for the result rows if returning records.</p> </li> <li> <p>fetch_df (bool) \u2013 defaults to <code>False</code></p> <p>If True, fetch the result as a pandas DataFrame and return it as a list of dictionaries.</p> </li> <li> <p>kwargs</p> <p>Additional keyword arguments to be passed to the SQL query, useful for string formatting.</p> </li> </ul>"},{"location":"api/evaluation/evaluate/","title":"evaluate","text":"<p>Evaluate the performance of document retrieval using relevance judgments.</p>"},{"location":"api/evaluation/evaluate/#parameters","title":"Parameters","text":"<ul> <li> <p>scores (list[list[dict]])</p> <p>A list of lists, where each sublist contains dictionaries representing the retrieved documents for a query.</p> </li> <li> <p>qrels (dict)</p> <p>A dictionary mapping queries to relevant documents and their relevance scores.</p> </li> <li> <p>queries (list[str])</p> <p>A list of queries.</p> </li> <li> <p>metrics (list) \u2013 defaults to <code>[]</code></p> <p>A list of metrics to compute. Default includes \"ndcg@10\" and hits at various levels (e.g., hits@1, hits@10).</p> </li> </ul>"},{"location":"api/evaluation/evaluate/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\"scifact\", split=\"test\")\n\n&gt;&gt;&gt; upload.documents(\n...     database=\"test.duckdb\",\n...     key=\"id\",\n...     fields=[\"title\", \"text\"],\n...     documents=documents,\n... )\n| Table          | Size |\n|----------------|------|\n| documents      | 5183 |\n| bm25_documents | 5183 |\n\n&gt;&gt;&gt; scores = search.documents(\n...     database=\"test.duckdb\",\n...     queries=queries,\n...     top_k=10,\n... )\n</code></pre>"},{"location":"api/evaluation/load-beir/","title":"load_beir","text":"<p>Load BEIR dataset for document and query retrieval tasks.</p>"},{"location":"api/evaluation/load-beir/#parameters","title":"Parameters","text":"<ul> <li> <p>dataset_name (str)</p> <p>The name of the dataset to load (e.g., 'scifact').</p> </li> <li> <p>split (str) \u2013 defaults to <code>test</code></p> <p>The dataset split to load (e.g., 'test').</p> </li> </ul>"},{"location":"api/evaluation/load-beir/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; documents, queries, qrels = load_beir(\"scifact\", split=\"test\")\n\n&gt;&gt;&gt; len(documents)\n5183\n\n&gt;&gt;&gt; len(queries)\n300\n</code></pre>"},{"location":"api/hf/insert-documents/","title":"insert_documents","text":"<p>Insert documents from a Hugging Face dataset into DuckDB.</p>"},{"location":"api/hf/insert-documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The schema in which the documents table is located.</p> </li> <li> <p>key (str)</p> <p>The key field that uniquely identifies each document (e.g., 'query_id').</p> </li> <li> <p>fields (str | list[str])</p> <p>A list of fields to be inserted from the dataset. If a single field is provided as a string, it will be converted to a list.</p> </li> <li> <p>url (str)</p> <p>The URL of the Hugging Face dataset in Parquet format.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> <li> <p>limit (int | None) \u2013 defaults to <code>None</code></p> </li> </ul>"},{"location":"api/hf/insert-documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import upload\n\n&gt;&gt;&gt; upload.documents(\n...     database=\"test.duckdb\",\n...     documents=\"hf://datasets/lightonai/lighton-ms-marco-mini/train.parquet\",\n...     fields=[\"document_ids\", \"scores\"],\n...     key=\"query_id\",\n... )\n| Table          | Size |\n|----------------|------|\n| documents      | 19   |\n| bm25_documents | 19   |\n</code></pre>"},{"location":"api/search/documents/","title":"documents","text":"<p>Search for documents in the documents table using specified queries.</p>"},{"location":"api/search/documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>queries (str | list[str])</p> <p>A string or list of query strings to search for.</p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>32</code></p> <p>The batch size for query processing.</p> </li> <li> <p>top_k (int) \u2013 defaults to <code>10</code></p> <p>The number of top documents to retrieve for each query.</p> </li> <li> <p>top_k_token (int) \u2013 defaults to <code>30000</code></p> <p>The number of documents to score per token.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>The number of parallel jobs to use. Default use all available processors.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration for DuckDB connection settings.</p> </li> <li> <p>filters (str | None) \u2013 defaults to <code>None</code></p> <p>Optional SQL filters to apply during the search.</p> </li> </ul>"},{"location":"api/search/documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\n...     \"scifact\",\n...     split=\"test\",\n... )\n\n&gt;&gt;&gt; scores = search.documents(\n...     database=\"test.duckdb\",\n...     queries=queries,\n...     top_k_token=1000,\n... )\n</code></pre>"},{"location":"api/search/graphs/","title":"graphs","text":"<p>Search for graphs in DuckDB using the provided queries.</p>"},{"location":"api/search/graphs/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>queries (str | list[str])</p> <p>A string or list of query strings to search for.</p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>30</code></p> <p>The batch size for processing queries.</p> </li> <li> <p>top_k (int) \u2013 defaults to <code>1000</code></p> <p>The number of top documents to retrieve for each query.</p> </li> <li> <p>top_k_token (int) \u2013 defaults to <code>30000</code></p> <p>The number of top tokens to retrieve.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>The number of parallel jobs to use. Default use all available processors.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration settings for the DuckDB connection.</p> </li> <li> <p>filters (str | None) \u2013 defaults to <code>None</code></p> <p>Optional SQL filters to apply during the search.</p> </li> </ul>"},{"location":"api/search/graphs/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\"scifact\", split=\"train\")\n\n&gt;&gt;&gt; upload.documents(\n...     database=\"test.duckdb\",\n...     key=\"id\",\n...     fields=[\"title\", \"text\"],\n...     documents=documents,\n... )\n| Table          | Size |\n|----------------|------|\n| documents      | 5183 |\n| bm25_documents | 5183 |\n\n&gt;&gt;&gt; upload.queries(\n...     database=\"test.duckdb\",\n...     queries=queries,\n...     documents_queries=qrels,\n... )\n| Table             | Size |\n|-------------------|------|\n| documents         | 5183 |\n| queries           | 807  |\n| bm25_documents    | 5183 |\n| bm25_queries      | 807  |\n| documents_queries | 916  |\n\n&gt;&gt;&gt; scores = search.graphs(\n...     database=\"test.duckdb\",\n...     queries=queries,\n...     top_k=10,\n... )\n</code></pre>"},{"location":"api/search/queries/","title":"queries","text":"<p>Search for queries in the queries table using specified queries.</p>"},{"location":"api/search/queries/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>queries (str | list[str])</p> <p>A string or list of query strings to search for.</p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>32</code></p> <p>The batch size for query processing.</p> </li> <li> <p>top_k (int) \u2013 defaults to <code>10</code></p> <p>The number of top matching queries to retrieve.</p> </li> <li> <p>top_k_token (int) \u2013 defaults to <code>30000</code></p> <p>The number of documents to score per token.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>The number of parallel jobs to use. Default use all available processors.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration for DuckDB connection settings.</p> </li> <li> <p>filters (str | None) \u2013 defaults to <code>None</code></p> <p>Optional SQL filters to apply during the search.</p> </li> </ul>"},{"location":"api/search/queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\"scifact\", split=\"test\")\n\n&gt;&gt;&gt; scores = search.queries(database=\"test.duckdb\", queries=queries)\n\n&gt;&gt;&gt; n = sum(1 for sample, query in zip(scores, queries) if sample[0][\"query\"] == query)\n&gt;&gt;&gt; assert n &gt;= 290\n</code></pre>"},{"location":"api/search/search/","title":"search","text":"<p>Run the search for documents or queries in parallel.</p>"},{"location":"api/search/search/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The name of the schema containing the indexed documents or queries.</p> </li> <li> <p>source_schema (str)</p> <p>The name of the schema containing the original documents or queries.</p> </li> <li> <p>source (str)</p> <p>The table to search (either 'documents' or 'queries').</p> </li> <li> <p>queries (str | list[str])</p> <p>A string or list of query strings to search for.</p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>64</code></p> <p>The batch size for query processing.</p> </li> <li> <p>top_k (int) \u2013 defaults to <code>10</code></p> <p>The number of top results to retrieve for each query.</p> </li> <li> <p>top_k_token (int) \u2013 defaults to <code>30000</code></p> <p>The number of documents to score per token.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>The number of parallel jobs to use. Default use available processors.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration for DuckDB connection settings.</p> </li> <li> <p>filters (str | None) \u2013 defaults to <code>None</code></p> <p>Optional SQL filters to apply during the search.</p> </li> </ul>"},{"location":"api/search/search/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import search\n\n&gt;&gt;&gt; documents = search.search(\n...     database=\"test.duckdb\",\n...     source_schema=\"bm25_tables\",\n...     schema=\"bm25_documents\",\n...     source=\"documents\",\n...     queries=\"random query\",\n...     top_k_token=10_000,\n...     top_k=10,\n... )\n\n&gt;&gt;&gt; assert len(documents) == 10\n</code></pre>"},{"location":"api/search/update-index-documents/","title":"update_index_documents","text":"<p>Update the BM25 search index for documents.</p>"},{"location":"api/search/update-index-documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>k1 (float) \u2013 defaults to <code>1.5</code></p> <p>The BM25 k1 parameter, controls term saturation.</p> </li> <li> <p>b (float) \u2013 defaults to <code>0.75</code></p> <p>The BM25 b parameter, controls document length normalization.</p> </li> <li> <p>stemmer (str) \u2013 defaults to <code>porter</code></p> <p>The stemming algorithm to use (e.g., 'porter').</p> </li> <li> <p>stopwords (str | list[str]) \u2013 defaults to <code>None</code></p> <p>The list of stopwords to exclude from indexing. Can be a list or a string specifying the language (e.g., \"english\").</p> </li> <li> <p>ignore (str) \u2013 defaults to <code>(\\.|[^a-z])+</code></p> <p>A regex pattern to ignore characters during tokenization. Default ignores punctuation and non-alphabetic characters.</p> </li> <li> <p>strip_accents (bool) \u2013 defaults to <code>True</code></p> <p>Whether to remove accents from characters during indexing.</p> </li> <li> <p>lower (bool) \u2013 defaults to <code>True</code></p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>10000</code></p> <p>The number of documents to process per batch.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration settings for the DuckDB connection.</p> </li> </ul>"},{"location":"api/search/update-index-documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\"scifact\", split=\"test\")\n\n&gt;&gt;&gt; upload.documents(\n...     database=\"test.duckdb\",\n...     key=\"id\",\n...     fields=[\"title\", \"text\"],\n...     documents=documents,\n...     stopwords=[\"larva\"],\n... )\n| Table          | Size |\n|----------------|------|\n| documents      | 5183 |\n| bm25_documents | 5183 |\n</code></pre>"},{"location":"api/search/update-index-queries/","title":"update_index_queries","text":"<p>Update the BM25 search index for queries.</p>"},{"location":"api/search/update-index-queries/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>k1 (float) \u2013 defaults to <code>1.5</code></p> <p>The BM25 k1 parameter, controls term saturation.</p> </li> <li> <p>b (float) \u2013 defaults to <code>0.75</code></p> <p>The BM25 b parameter, controls document length normalization.</p> </li> <li> <p>stemmer (str) \u2013 defaults to <code>porter</code></p> <p>The stemming algorithm to use (e.g., 'porter').</p> </li> <li> <p>stopwords (str | list[str]) \u2013 defaults to <code>None</code></p> <p>The list of stopwords to exclude from indexing. Can be a list or a string specifying the language (e.g., \"english\").</p> </li> <li> <p>ignore (str) \u2013 defaults to <code>(\\.|[^a-z])+</code></p> <p>A regex pattern to ignore characters during tokenization. Default ignores punctuation and non-alphabetic characters.</p> </li> <li> <p>strip_accents (bool) \u2013 defaults to <code>True</code></p> <p>Whether to remove accents from characters during indexing.</p> </li> <li> <p>lower (bool) \u2013 defaults to <code>True</code></p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>10000</code></p> <p>The number of queries to process per batch.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration settings for the DuckDB connection.</p> </li> </ul>"},{"location":"api/search/update-index-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import evaluation, upload, search\n\n&gt;&gt;&gt; documents, queries, qrels = evaluation.load_beir(\"scifact\", split=\"test\")\n\n&gt;&gt;&gt; upload.queries(\n...     database=\"test.duckdb\",\n...     queries=queries,\n...     documents_queries=qrels,\n... )\n| Table             | Size |\n|-------------------|------|\n| documents         | 5183 |\n| queries           | 300  |\n| bm25_documents    | 5183 |\n| bm25_queries      | 300  |\n| documents_queries | 339  |\n</code></pre>"},{"location":"api/tables/create-documents-queries/","title":"create_documents_queries","text":"<p>Create the documents_queries table in the DuckDB database.</p>"},{"location":"api/tables/create-documents-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; tables.create_schema(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\"\n... )\n\n&gt;&gt;&gt; tables.create_documents_queries(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n</code></pre>"},{"location":"api/tables/create-documents/","title":"create_documents","text":"<p>Create the documents table in the DuckDB database.</p>"},{"location":"api/tables/create-documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> </li> <li> <p>schema (str)</p> </li> <li> <p>fields (str | list[str])</p> </li> <li> <p>dtypes (dict[str, str] | None) \u2013 defaults to <code>None</code></p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> </li> </ul>"},{"location":"api/tables/create-documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; tables.create_schema(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\"\n... )\n\n&gt;&gt;&gt; tables.create_documents(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n...     fields=[\"title\", \"text\"],\n...     dtypes={\"text\": \"VARCHAR\", \"title\": \"VARCHAR\"},\n... )\n\n&gt;&gt;&gt; df = [\n...     {\"id\": 1, \"title\": \"title document 1\", \"text\": \"text document 1\"},\n...     {\"id\": 2, \"title\": \"title document 2\", \"text\": \"text document 2\"},\n...     {\"id\": 3, \"title\": \"title document 3\", \"text\": \"text document 3\"},\n... ]\n\n&gt;&gt;&gt; tables.insert_documents(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n...     key=\"id\",\n...     df=df,\n...     fields=[\"title\", \"text\"],\n... )\n</code></pre>"},{"location":"api/tables/create-queries/","title":"create_queries","text":"<p>Create the queries table in the DuckDB database.</p>"},{"location":"api/tables/create-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; tables.create_schema(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\"\n... )\n\n&gt;&gt;&gt; tables.create_queries(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n</code></pre>"},{"location":"api/tables/create-schema/","title":"create_schema","text":"<p>Create the specified schema in the DuckDB database.</p>"},{"location":"api/tables/create-schema/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> </li> <li> <p>schema (str)</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> </li> </ul>"},{"location":"api/tables/create-schema/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; tables.create_schema(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n</code></pre>"},{"location":"api/tables/insert-documents-queries/","title":"insert_documents_queries","text":"<p>Insert interactions between documents and queries into the documents_queries table.</p>"},{"location":"api/tables/insert-documents-queries/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The schema in which the documents_queries table is located.</p> </li> <li> <p>documents_queries (dict[dict[str, float]])</p> <p>A dictionary mapping document IDs to queries and their corresponding scores.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> </ul>"},{"location":"api/tables/insert-documents-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; documents_queries = {\n...     \"1\": {\"query 1\": 0.9, \"query 2\": 0.8},\n...     \"2\": {\"query 2\": 0.9, \"query 3\": 3},\n...     \"3\": {\"query 1\": 0.9, \"query 3\": 0.5},\n... }\n\n&gt;&gt;&gt; tables.insert_documents_queries(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n...     documents_queries=documents_queries\n... )\n</code></pre>"},{"location":"api/tables/insert-documents/","title":"insert_documents","text":"<p>Insert documents into the documents table with optional multi-threading.</p>"},{"location":"api/tables/insert-documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The schema in which the documents table is located.</p> </li> <li> <p>df (list[dict] | str)</p> <p>The list of document dictionaries or a string (URL) for a Hugging Face dataset to insert.</p> </li> <li> <p>key (str)</p> <p>The field that uniquely identifies each document (e.g., 'id').</p> </li> <li> <p>fields (list[str] | str)</p> <p>The list of document fields to insert. Can be a string if inserting a single field.</p> </li> <li> <p>dtypes (dict[str, str] | None) \u2013 defaults to <code>None</code></p> <p>Optional dictionary specifying the DuckDB type for each field. Defaults to 'VARCHAR' for all unspecified fields.</p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>30000</code></p> <p>The number of documents to insert in each batch.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>Number of parallel jobs to use for inserting documents. Default use all available processors.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> <li> <p>limit (int | None) \u2013 defaults to <code>None</code></p> </li> </ul>"},{"location":"api/tables/insert-documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; df = [\n...     {\"id\": 1, \"title\": \"title document 1\", \"text\": \"text document 1\"},\n...     {\"id\": 2, \"title\": \"title document 2\", \"text\": \"text document 2\"},\n...     {\"id\": 3, \"title\": \"title document 3\", \"text\": \"text document 3\"},\n... ]\n\n&gt;&gt;&gt; _ = tables.insert_documents(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n...     key=\"id\",\n...     fields=[\"title\", \"text\"],\n...     df=df\n... )\n</code></pre>"},{"location":"api/tables/insert-queries/","title":"insert_queries","text":"<p>Insert a list of queries into the queries table.</p>"},{"location":"api/tables/insert-queries/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The schema in which the queries table is located.</p> </li> <li> <p>queries (list[str])</p> <p>A list of query strings to insert into the table.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> </ul>"},{"location":"api/tables/insert-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; _ = tables.insert_queries(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n...     queries=[\"query 1\", \"query 2\", \"query 3\"],\n... )\n</code></pre>"},{"location":"api/tables/select-documents-columns/","title":"select_documents_columns","text":"<p>Select the column names from the documents table, excluding the 'bm25id' column.</p>"},{"location":"api/tables/select-documents-columns/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>schema (str)</p> <p>The schema where the documents table is located.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> </ul>"},{"location":"api/tables/select-documents-columns/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; tables.select_documents_columns(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n['id', 'title', 'text']\n</code></pre>"},{"location":"api/tables/select-documents/","title":"select_documents","text":"<p>Select all documents from the documents table.</p>"},{"location":"api/tables/select-documents/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; documents = tables.select_documents(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n\n&gt;&gt;&gt; assert len(documents) == 3\n</code></pre>"},{"location":"api/tables/select-queries/","title":"select_queries","text":"<p>Select all queries from the queries table.</p>"},{"location":"api/tables/select-queries/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import tables\n\n&gt;&gt;&gt; queries = tables.select_queries(\n...     database=\"test.duckdb\",\n...     schema=\"bm25_tables\",\n... )\n\n&gt;&gt;&gt; assert len(queries) == 3\n</code></pre>"},{"location":"api/upload/documents/","title":"documents","text":"<p>Upload documents to DuckDB, create necessary schema, and index using BM25.</p>"},{"location":"api/upload/documents/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>Name of the DuckDB database.</p> </li> <li> <p>key (str)</p> <p>Key identifier for the documents. The key will be renamed to <code>id</code> in the database.</p> </li> <li> <p>fields (str | list[str])</p> <p>List of fields to upload from each document. If a single field is provided as a string, it will be converted to a list.</p> </li> <li> <p>documents (list[dict] | str)</p> <p>Documents to upload. Can be a list of dictionaries or a Hugging Face (HF) URL string pointing to a dataset.</p> </li> <li> <p>k1 (float) \u2013 defaults to <code>1.5</code></p> <p>BM25 k1 parameter, controls term saturation.</p> </li> <li> <p>b (float) \u2013 defaults to <code>0.75</code></p> <p>BM25 b parameter, controls document length normalization.</p> </li> <li> <p>stemmer (str) \u2013 defaults to <code>porter</code></p> <p>Stemming algorithm to use (e.g., 'porter'). The type of stemmer to be used. One of 'arabic', 'basque', 'catalan', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hindi', 'hungarian', 'indonesian', 'irish', 'italian', 'lithuanian', 'nepali', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'serbian', 'spanish', 'swedish', 'tamil', 'turkish', or 'none' if no stemming is to be used.</p> </li> <li> <p>stopwords (str | list[str]) \u2013 defaults to <code>None</code></p> <p>List of stopwords to exclude from indexing.  Can be a custom list or a language string.</p> </li> <li> <p>ignore (str) \u2013 defaults to <code>(\\.|[^a-z])+</code></p> <p>Regular expression pattern to ignore characters when indexing. Default ignore punctuation and non-alphabetic characters.</p> </li> <li> <p>strip_accents (bool) \u2013 defaults to <code>True</code></p> <p>Whether to remove accents from characters during indexing.</p> </li> <li> <p>lower (bool) \u2013 defaults to <code>True</code></p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>30000</code></p> <p>Number of documents to process per batch.</p> </li> <li> <p>n_jobs (int) \u2013 defaults to <code>-1</code></p> <p>Number of parallel jobs to use for uploading documents. Default use all available processors.</p> </li> <li> <p>dtypes (dict[str, str] | None) \u2013 defaults to <code>None</code></p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration dictionary for the DuckDB connection and other settings.</p> </li> <li> <p>limit (int | None) \u2013 defaults to <code>None</code></p> </li> </ul>"},{"location":"api/upload/queries/","title":"queries","text":"<p>Upload queries to DuckDB, map documents to queries, and index using BM25.</p>"},{"location":"api/upload/queries/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>Name of the DuckDB database.</p> </li> <li> <p>queries (list[str] | None) \u2013 defaults to <code>None</code></p> <p>List of queries to upload. Each query is a string.</p> </li> <li> <p>documents_queries (dict[list]) \u2013 defaults to <code>None</code></p> <p>Dictionary mapping document IDs to a list of queries.</p> </li> <li> <p>k1 (float) \u2013 defaults to <code>1.5</code></p> <p>BM25 k1 parameter, controls term saturation.</p> </li> <li> <p>b (float) \u2013 defaults to <code>0.75</code></p> <p>BM25 b parameter, controls document length normalization.</p> </li> <li> <p>stemmer (str) \u2013 defaults to <code>porter</code></p> <p>Stemming algorithm to use (e.g., 'porter'). The type of stemmer to be used. One of 'arabic', 'basque', 'catalan', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hindi', 'hungarian', 'indonesian', 'irish', 'italian', 'lithuanian', 'nepali', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'serbian', 'spanish', 'swedish', 'tamil', 'turkish', or 'none' if no stemming is to be used.</p> </li> <li> <p>stopwords (str | list[str]) \u2013 defaults to <code>None</code></p> <p>List of stopwords to exclude from indexing. Default can be a custom list or a language string.</p> </li> <li> <p>ignore (str) \u2013 defaults to <code>(\\.|[^a-z])+</code></p> <p>Regular expression pattern to ignore characters when indexing. Default ignore punctuation and non-alphabetic characters.</p> </li> <li> <p>strip_accents (bool) \u2013 defaults to <code>True</code></p> <p>Whether to remove accents from characters during indexing.</p> </li> <li> <p>lower (bool) \u2013 defaults to <code>True</code></p> </li> <li> <p>batch_size (int) \u2013 defaults to <code>30000</code></p> <p>Number of queries to process per batch.</p> </li> <li> <p>config (dict | None) \u2013 defaults to <code>None</code></p> <p>Optional configuration dictionary for the DuckDB connection and other settings.</p> </li> </ul>"},{"location":"api/utils/batchify/","title":"batchify","text":"<p>Split a list into batches and optionally display a progress bar.</p>"},{"location":"api/utils/batchify/#parameters","title":"Parameters","text":"<ul> <li> <p>X (list[str])</p> <p>A list of items to be batched.</p> </li> <li> <p>batch_size (int)</p> <p>The number of items in each batch.</p> </li> <li> <p>desc (str) \u2013 defaults to ``</p> <p>A description to display in the progress bar.</p> </li> <li> <p>tqdm_bar (bool) \u2013 defaults to <code>True</code></p> <p>Whether to display a progress bar using <code>tqdm</code>.</p> </li> </ul>"},{"location":"api/utils/batchify/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; items = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n&gt;&gt;&gt; batches = list(batchify(items, batch_size=2))\n&gt;&gt;&gt; for batch in batches:\n...     print(batch)\n['a', 'b']\n['c', 'd']\n['e', 'f']\n</code></pre>"},{"location":"api/utils/plot/","title":"plot","text":"<p>Generate and display a markdown table with statistics of the specified dataset tables.</p>"},{"location":"api/utils/plot/#parameters","title":"Parameters","text":"<ul> <li> <p>database (str)</p> <p>The name of the DuckDB database.</p> </li> <li> <p>config (None | dict) \u2013 defaults to <code>None</code></p> <p>Optional configuration options for the DuckDB connection.</p> </li> <li> <p>tables \u2013 defaults to <code>['bm25_tables.documents', 'bm25_tables.queries', 'bm25_documents.lengths', 'bm25_queries.lengths', 'bm25_tables.documents_queries']</code></p> <p>A list of table names to plot statistics for. Defaults to common BM25 tables.</p> </li> </ul>"},{"location":"api/utils/plot/#examples","title":"Examples","text":"<pre><code>&gt;&gt;&gt; from ducksearch import utils\n\n&gt;&gt;&gt; utils.plot(database=\"test.duckdb\")\n| Table     | Size |\n|-----------|------|\n| documents | 5183 |\n| queries   | 300  |\n</code></pre>"},{"location":"benchmarks/benchmarks/","title":"Benchmarks","text":""},{"location":"benchmarks/benchmarks/#benchmarks","title":"Benchmarks","text":""},{"location":"benchmarks/benchmarks/#ducksearch-and-bm25s","title":"Ducksearch and BM25s","text":"<p>While DuckSearch provide advanced filtering features / updates on the index, DuckSearch only score <code>top_k_token</code> document per query token. Benchmark might evolve with DuckDB improvements and DuckSearch updates.</p> Table Dataset Metric Ducksearch BM25s Difference (Ducksearch - BM25s) arguana ndcg@10 0.3779 0.3663 +0.0116 hits@1 0.0 0.0 0.0 mrr@10 0.2491 0.2443 +0.0048 map@10 0.2528 0.2430 +0.0098 qps 117.80 2113.50 -1995.70 Index Time(s) 1.42 0.48 +0.94 climate-fever ndcg@10 0.1184 0.1313 -0.0129 hits@1 0.1068 0.1186 -0.0118 mrr@10 0.1644 0.1809 -0.0165 map@10 0.0803 0.0907 -0.0104 qps 5.88 99.49 -93.61 Index Time(s) 302.39 209.97 +92.42 dbpedia-entity ndcg@10 0.6046 0.6172 -0.0126 hits@1 0.7669 0.7744 -0.0075 mrr@10 0.8311 0.8382 -0.0071 map@10 0.0649 0.0672 -0.0023 qps 113.20 182.79 -69.59 Index Time(s) 181.42 119.18 +62.24 fever ndcg@10 0.3861 0.4825 -0.0964 hits@1 0.2583 0.3312 -0.0729 mrr@10 0.3525 0.4423 -0.0898 map@10 0.3329 0.4212 -0.0883 qps 74.40 104.97 -30.57 Index Time(s) 329.70 207.52 +122.18 fiqa ndcg@10 0.2445 0.2326 +0.0119 hits@1 0.2207 0.2160 +0.0047 mrr@10 0.3002 0.2875 +0.0127 map@10 0.1848 0.1726 +0.0122 qps 545.77 2157.35 -1611.58 Index Time(s) 6.04 4.27 +1.77 hotpotqa ndcg@10 0.4487 0.5630 -0.1143 hits@1 0.5059 0.6523 -0.1464 mrr@10 0.5846 0.7249 -0.1403 map@10 0.3642 0.4697 -0.1055 qps 48.15 104.43 -56.28 Index Time(s) 163.14 123.39 +39.75 msmarco ndcg@10 0.8951 0.9705 -0.0754 hits@1 1.0 1.0 0.0 mrr@10 1.0 1.0 0.0 map@10 0.0459 0.0532 -0.0073 qps 35.11 71.26 -36.15 Index Time(s) 202.37 229.22 -26.85 nfcorpus ndcg@10 0.3301 0.3059 +0.0242 hits@1 0.4396 0.4458 -0.0062 mrr@10 0.5292 0.5205 +0.0087 map@10 0.1233 0.1168 +0.0065 qps 3464.66 3933.12 -468.46 Index Time(s) 0.99 1.67 -0.68 nq ndcg@10 0.2451 0.2735 -0.0284 hits@1 0.1272 0.1460 -0.0188 mrr@10 0.2099 0.2366 -0.0267 map@10 0.1934 0.2177 -0.0243 qps 150.23 272.62 -122.39 Index Time(s) 71.43 87.98 -16.55 quora ndcg@10 0.7705 0.7491 +0.0214 hits@1 0.6783 0.6622 +0.0161 mrr@10 0.7606 0.7433 +0.0173 map@10 0.7206 0.6988 +0.0218 qps 741.13 1004.44 -263.31 Index Time(s) 3.78 6.57 -2.79 scidocs ndcg@10 0.1025 0.0993 +0.0032 hits@1 0.1790 0.1910 -0.0120 mrr@10 0.2754 0.2765 -0.0011 map@10 0.0154 0.0147 +0.0007 qps 879.11 3570.06 -2690.95 Index Time(s) 4.46 1.64 +2.82 scifact ndcg@10 0.6908 0.6617 +0.0291 hits@1 0.5533 0.5433 +0.0100 mrr@10 0. 6527 0.6312 +0.0215 map@10 0.6416 0.6199 +0.0217 qps 2153.64 3708.28 -1554.64 Index Time(s) 1.22 0.41 +0.81 trec-covid ndcg@10 0.9533 0.8983 +0.0550 hits@1 1.0 0.92 +0.08 mrr@10 1.0 0.96 +0.04 map@10 0.0074 0.0069 +0.0005 qps 112.38 1275.41 -1163.03 Index Time(s) 22.15 10.15 +12.00 webis-touche2020 ndcg@10 0.4130 0.4671 -0.0541 hits@1 0.5510 0.6122 -0.0612 mrr@10 0.7114 0.7541 -0.0427 map@10 0.0564 0.0659 -0.0095 qps 104.65 961.73 -857.08 Index Time(s) 44.14 34.89 +9.25"},{"location":"documentation/delete/","title":"Delete","text":""},{"location":"documentation/delete/#delete","title":"Delete","text":"<p>To delete a document, you need to provide the document's ID. The delete operation will remove the document from the database and update the index.</p> <pre><code>from ducksearch import delete, upload\n\ndelete.documents(\n    database=\"ducksearch.duckdb\",\n    ids=[0, 1],\n)\n</code></pre>"},{"location":"documentation/graph/","title":"Graph","text":""},{"location":"documentation/graph/#graph","title":"Graph","text":"<p>The <code>search.graphs</code> function can be used to search documents with a graph-based query. This function is useful if we have paired documents and queries. The search will retrieve the set of documents and queries that match the input query. Then it will build a graph and compute the weight of each document using a graph-based scoring function.</p> <p>The <code>search.graphs</code> function is much slower than the <code>search.documents</code> function, but might provide better results with decent amount of paired documents / queries.</p>"},{"location":"documentation/graph/#documents-queries-interactions","title":"Documents queries interactions","text":"<p>We can upload documents queries interactions in order to call the <code>search.graphs</code> function. The following example demonstrates how to upload documents queries interactions:</p> <pre><code>from ducksearch import search, upload\n\ndocuments = [\n    {\n        \"id\": 0,\n        \"title\": \"Hotel California\",\n        \"style\": \"rock\",\n        \"date\": \"1977-02-22\",\n        \"popularity\": 9,\n    },\n    {\n        \"id\": 1,\n        \"title\": \"Here Comes the Sun\",\n        \"style\": \"rock\",\n        \"date\": \"1969-06-10\",\n        \"popularity\": 10,\n    },\n    {\n        \"id\": 2,\n        \"title\": \"Alive\",\n        \"style\": \"electro, punk\",\n        \"date\": \"2007-11-19\",\n        \"popularity\": 9,\n    },\n]\n\nupload.documents(\n    database=\"ducksearch.duckdb\",\n    key=\"id\",\n    fields=[\"title\", \"style\", \"date\", \"popularity\"],\n    documents=documents,\n    dtypes={\n        \"date\": \"DATE\",\n        \"popularity\": \"INT\",\n    },\n)\n\n# Mapping between documents ids and queries\ndocuments_queries = {\n    0: [\"the beatles\", \"rock band\"],\n    1: [\"rock band\", \"california\"],\n    2: [\"daft\"],\n}\n\nupload.queries(\n    database=\"ducksearch.duckdb\",\n    documents_queries=documents_queries,\n)\n</code></pre> Tip <p>We can write documents queries mapping as a list of dict with the weight between the document and the query. The weight is used to compute the score in the <code>search.graphs</code> function:</p> <pre><code>documents_queries = {\n    0: {\"the beatles\": 30, \"rock band\": 10},\n    1: {\"rock band\": 10, \"california\": 1},\n    2: {\"daft\": 60},\n}\n</code></pre> <p>When the weight is not specified, the default value is 1.</p>"},{"location":"documentation/graph/#search-graphs","title":"Search Graphs","text":"<p>The following example demonstrates how to search documents with a graph-based query:</p> <pre><code>from ducksearch import search\n\nsearch.graphs(\n    database=\"ducksearch.duckdb\",\n    queries=\"daft punk\",\n    top_k=10,\n)\n</code></pre> <pre><code>[\n    {\n        \"id\": \"2\",\n        \"title\": \"Alive\",\n        \"style\": \"electro, punk\",\n        \"date\": Timestamp(\"2007-11-19 00:00:00\"),\n        \"popularity\": 9,\n        \"score\": 2.877532958984375,\n    }\n]\n</code></pre>"},{"location":"documentation/search/","title":"Search","text":"Note <p>Before we can search for documents, we need to upload them to DuckDB. We can use the <code>upload.documents</code> function to upload a list of dictionaries to DuckDB.</p>"},{"location":"documentation/search/#search","title":"Search","text":"<p>All the search functions require a DuckDB database name as the first argument. The database name is the name of the DuckDB database where the documents are stored. The database name is the same as the one used in the <code>upload.documents</code> function. Each search function can take additional parameters to control the search behavior such as the number of documents to return, the number of documents to score for each query token, and the number of parallel jobs to use as well as optional SQL filters.</p>"},{"location":"documentation/search/#documents","title":"Documents","text":"<p>Once the documents are uploaded, we can search for them using the <code>search.documents</code> function. The search function returns a list of list of documents ordered by their BM25 score.</p> <pre><code>search.documents(\n    database=\"ducksearch.duckdb\",\n    queries=[\"daft punk\", \"rock\"],\n    top_k=10,\n    top_k_token=10_000,\n    batch_size=32,\n    n_jobs=-1,\n)\n</code></pre> <pre><code>[\n    [\n        {\n            \"id\": \"2\",\n            \"title\": \"Alive\",\n            \"style\": \"electro, punk\",\n            \"date\": Timestamp(\"2007-11-19 00:00:00\"),\n            \"popularity\": 9,\n            \"score\": 0.16131360828876495,\n        }\n    ],\n    [\n        {\n            \"id\": \"1\",\n            \"title\": \"Here Comes the Sun\",\n            \"style\": \"rock\",\n            \"date\": Timestamp(\"1969-06-10 00:00:00\"),\n            \"popularity\": 10,\n            \"score\": 0.09199773520231247,\n        },\n        {\n            \"id\": \"0\",\n            \"title\": \"Hotel California\",\n            \"style\": \"rock\",\n            \"date\": Timestamp(\"1977-02-22 00:00:00\"),\n            \"popularity\": 9,\n            \"score\": 0.07729987800121307,\n        },\n    ],\n]\n</code></pre> Info <p>The search function is executed in parallel using the <code>n_jobs</code> parameter. We can control the number of documents to return using the <code>top_k</code> parameter and the number of documents to score for each query token using the <code>top_k_token</code> parameter. Reducing <code>top_k_token</code> can further speed up the search but may result in lower quality results.</p>"},{"location":"documentation/search/#filters","title":"Filters","text":"<p>We can apply filters to the search using the <code>filters</code> parameter. The filters are SQL expressions that are applied to the search results.</p> <pre><code>from ducksearch import search\n\nsearch.documents(\n    database=\"ducksearch.duckdb\",\n    queries=[\"rock\", \"california\"],\n    top_k=10,\n    top_k_token=10_000,\n    batch_size=32,\n    filters=\"YEAR(date) &lt;= 1990 AND YEAR(date) &gt;= 1970\",\n    n_jobs=-1,\n)\n</code></pre> <pre><code>[\n    [\n        {\n            \"score\": 0.07729987800121307,\n            \"id\": \"0\",\n            \"title\": \"Hotel California\",\n            \"style\": \"rock\",\n            \"date\": Timestamp(\"1977-02-22 00:00:00\"),\n            \"popularity\": 9,\n        }\n    ],\n    [\n        {\n            \"score\": 0.16131360828876495,\n            \"id\": \"0\",\n            \"title\": \"Hotel California\",\n            \"style\": \"rock\",\n            \"date\": Timestamp(\"1977-02-22 00:00:00\"),\n            \"popularity\": 9,\n        }\n    ],\n]\n</code></pre> Info <p>The filters are evaluated by DuckDB, so all DuckDB functions are available for use in the filters. You can find more information about DuckDB functions in the DuckDB documentation.</p>"},{"location":"documentation/update/","title":"Update","text":""},{"location":"documentation/update/#update","title":"Update","text":"<p>To update a document, you to first delete the document and then upload the updated document. The delete operation will remove the document from the database and update the index. Finally, the upload operation will add the updated document to the database and update the index.</p> <pre><code>from ducksearch import delete, upload\n\ndelete.documents(\n    database=\"ducksearch.duckdb\",\n    ids=[0, 1],\n)\n\ndocuments_updated = [\n    {\n        \"id\": 0,\n        \"title\": \"Hotel California\",\n        \"style\": \"rock\",\n        \"date\": \"1977-02-22\",\n        \"popularity\": 9,\n    },\n    {\n        \"id\": 1,\n        \"title\": \"Here Comes the Sun\",\n        \"style\": \"rock\",\n        \"date\": \"1969-06-10\",\n        \"popularity\": 10,\n    },\n]\n\nupload.documents(\n    database=\"ducksearch.duckdb\",\n    key=\"id\",\n    fields=[\"title\", \"style\", \"date\", \"popularity\"],\n    documents=documents_updated,\n    dtypes={\n        \"date\": \"DATE\",\n        \"popularity\": \"INT\",\n    },\n)\n</code></pre>"},{"location":"documentation/upload/","title":"Upload","text":""},{"location":"documentation/upload/#upload","title":"Upload","text":"<p>When working with DuckSearch, the first step is to upload documents to DuckDB using the <code>upload.documents</code> function. The documents are stored in a DuckDB database, and the fields are indexed with BM25. DuckSearch won't re-index a document if it already exists in the database. Index will be updated along with the new documents.</p>"},{"location":"documentation/upload/#upload-documents","title":"Upload documents","text":"<p>The following example demonstrates how to upload a list of documents:</p> <pre><code>from ducksearch import upload\n\ndocuments = [\n    {\n        \"id\": 0,\n        \"title\": \"Hotel California\",\n        \"style\": \"rock\",\n        \"date\": \"1977-02-22\",\n        \"popularity\": 9,\n    },\n    {\n        \"id\": 1,\n        \"title\": \"Here Comes the Sun\",\n        \"style\": \"rock\",\n        \"date\": \"1969-06-10\",\n        \"popularity\": 10,\n    },\n    {\n        \"id\": 2,\n        \"title\": \"Alive\",\n        \"style\": \"electro, punk\",\n        \"date\": \"2007-11-19\",\n        \"popularity\": 9,\n    },\n]\n\nupload.documents(\n    database=\"ducksearch.duckdb\",\n    key=\"id\", # unique document identifier\n    fields=[\"title\", \"style\", \"date\", \"popularity\"], # list of fields to index\n    documents=documents,\n    stopwords=\"english\",\n    stemmer=\"porter\",\n    lower=True,\n    strip_accents=True,\n    dtypes={\n        \"date\": \"DATE\",\n        \"popularity\": \"INT\",\n    },\n)\n</code></pre> Info <p>stopwords: List of stop words to filter Defaults to 'english' for a pre-defined list of 571 English stopwords.</p> <p>stemmer: Stemmer to use. Defaults to 'porter' for the Porter stemmer. Possible values are: 'arabic', 'basque', 'catalan', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hindi', 'hungarian', 'indonesian', 'irish', 'italian', 'lithuanian', 'nepali', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'serbian', 'spanish', 'swedish', 'tamil', 'turkish', or <code>None</code> if no stemming is to be used.</p> <p>lower: Whether to convert the text to lowercase. Defaults to <code>True</code>.</p> <p>strip_accents: Whether to strip accents from the text. Defaults to <code>True</code>.</p>"},{"location":"documentation/upload/#huggingface","title":"HuggingFace","text":"<p>The <code>upload.documents</code> function can also index HuggingFace datasets directly from the url.  The following example demonstrates how to index the FineWeb dataset from HuggingFace:</p> <pre><code>from ducksearch import upload\n\nupload.documents(\n    database=\"fineweb.duckdb\",\n    key=\"id\",\n    fields=[\"text\", \"url\", \"date\", \"language\", \"token_count\", \"language_score\"],\n    documents=\"https://huggingface.co/datasets/HuggingFaceFW/fineweb/resolve/main/sample/10BT/000_00000.parquet\",\n    dtypes={\n        \"date\": \"DATE\",\n        \"token_count\": \"INT\",\n        \"language_score\": \"FLOAT\",\n    },\n    limit=1000, # demonstrate with a small dataset\n)\n</code></pre> Info <p>More informations about DuckDB and HuggingFace compatibility can be found here and here.</p>"},{"location":"parse/__main__/","title":"main","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"This script is responsible for building the API reference. The API reference is located in\ndocs/api. The script scans through all the modules, classes, and functions. It processes\nthe __doc__ of each object and formats it so that MkDocs can process it in turn.\n\"\"\"\n</pre> \"\"\"This script is responsible for building the API reference. The API reference is located in docs/api. The script scans through all the modules, classes, and functions. It processes the __doc__ of each object and formats it so that MkDocs can process it in turn. \"\"\" In\u00a0[\u00a0]: Copied! <pre>import functools\nimport importlib\nimport inspect\nimport os\nimport pathlib\nimport re\nimport shutil\n</pre> import functools import importlib import inspect import os import pathlib import re import shutil In\u00a0[\u00a0]: Copied! <pre>from numpydoc.docscrape import ClassDoc, FunctionDoc\n</pre> from numpydoc.docscrape import ClassDoc, FunctionDoc In\u00a0[\u00a0]: Copied! <pre>package = \"ducksearch\"\n</pre> package = \"ducksearch\" In\u00a0[\u00a0]: Copied! <pre>shutil.copy(\"README.md\", \"docs/index.md\")\n</pre> shutil.copy(\"README.md\", \"docs/index.md\") In\u00a0[\u00a0]: Copied! <pre>with open(\"docs/index.md\", mode=\"r\") as file:\n    content = file.read()\n</pre> with open(\"docs/index.md\", mode=\"r\") as file:     content = file.read() In\u00a0[\u00a0]: Copied! <pre>with open(\"docs/index.md\", mode=\"w\") as file:\n    file.write(content.replace(\"docs/img/logo.png\", \"img/logo.png\"))\n</pre> with open(\"docs/index.md\", mode=\"w\") as file:     file.write(content.replace(\"docs/img/logo.png\", \"img/logo.png\")) In\u00a0[\u00a0]: Copied! <pre>def paragraph(text):\n    return f\"{text}\\n\"\n</pre> def paragraph(text):     return f\"{text}\\n\" In\u00a0[\u00a0]: Copied! <pre>def h1(text):\n    return paragraph(f\"# {text}\")\n</pre> def h1(text):     return paragraph(f\"# {text}\") In\u00a0[\u00a0]: Copied! <pre>def h2(text):\n    return paragraph(f\"## {text}\")\n</pre> def h2(text):     return paragraph(f\"## {text}\") In\u00a0[\u00a0]: Copied! <pre>def h3(text):\n    return paragraph(f\"### {text}\")\n</pre> def h3(text):     return paragraph(f\"### {text}\") In\u00a0[\u00a0]: Copied! <pre>def h4(text):\n    return paragraph(f\"#### {text}\")\n</pre> def h4(text):     return paragraph(f\"#### {text}\") In\u00a0[\u00a0]: Copied! <pre>def link(caption, href):\n    return f\"[{caption}]({href})\"\n</pre> def link(caption, href):     return f\"[{caption}]({href})\" In\u00a0[\u00a0]: Copied! <pre>def code(text):\n    return f\"`{text}`\"\n</pre> def code(text):     return f\"`{text}`\" In\u00a0[\u00a0]: Copied! <pre>def li(text):\n    return f\"- {text}\\n\"\n</pre> def li(text):     return f\"- {text}\\n\" In\u00a0[\u00a0]: Copied! <pre>def snake_to_kebab(text):\n    return text.replace(\"_\", \"-\")\n</pre> def snake_to_kebab(text):     return text.replace(\"_\", \"-\") In\u00a0[\u00a0]: Copied! <pre>def inherit_docstring(c, meth):\n    \"\"\"Since Python 3.5, inspect.getdoc is supposed to return the docstring from a parent class\n    if a class has none. However this doesn't seem to work for Cython classes.\n    \"\"\"\n\n    doc = None\n\n    for ancestor in inspect.getmro(c):\n        try:\n            ancestor_meth = getattr(ancestor, meth)\n        except AttributeError:\n            break\n        doc = inspect.getdoc(ancestor_meth)\n        if doc:\n            break\n\n    return doc\n</pre> def inherit_docstring(c, meth):     \"\"\"Since Python 3.5, inspect.getdoc is supposed to return the docstring from a parent class     if a class has none. However this doesn't seem to work for Cython classes.     \"\"\"      doc = None      for ancestor in inspect.getmro(c):         try:             ancestor_meth = getattr(ancestor, meth)         except AttributeError:             break         doc = inspect.getdoc(ancestor_meth)         if doc:             break      return doc In\u00a0[\u00a0]: Copied! <pre>def inherit_signature(c, method_name):\n    m = getattr(c, method_name)\n    sig = inspect.signature(m)\n\n    params = []\n\n    for param in sig.parameters.values():\n        if param.name == \"self\" or param.annotation is not param.empty:\n            params.append(param)\n            continue\n\n        for ancestor in inspect.getmro(c):\n            try:\n                ancestor_meth = inspect.signature(getattr(ancestor, m.__name__))\n            except AttributeError:\n                break\n            try:\n                ancestor_param = ancestor_meth.parameters[param.name]\n            except KeyError:\n                break\n            if ancestor_param.annotation is not param.empty:\n                param = param.replace(annotation=ancestor_param.annotation)\n                break\n\n        params.append(param)\n\n    return_annotation = sig.return_annotation\n    if return_annotation is inspect._empty:\n        for ancestor in inspect.getmro(c):\n            try:\n                ancestor_meth = inspect.signature(getattr(ancestor, m.__name__))\n            except AttributeError:\n                break\n            if ancestor_meth.return_annotation is not inspect._empty:\n                return_annotation = ancestor_meth.return_annotation\n                break\n\n    return sig.replace(parameters=params, return_annotation=return_annotation)\n</pre> def inherit_signature(c, method_name):     m = getattr(c, method_name)     sig = inspect.signature(m)      params = []      for param in sig.parameters.values():         if param.name == \"self\" or param.annotation is not param.empty:             params.append(param)             continue          for ancestor in inspect.getmro(c):             try:                 ancestor_meth = inspect.signature(getattr(ancestor, m.__name__))             except AttributeError:                 break             try:                 ancestor_param = ancestor_meth.parameters[param.name]             except KeyError:                 break             if ancestor_param.annotation is not param.empty:                 param = param.replace(annotation=ancestor_param.annotation)                 break          params.append(param)      return_annotation = sig.return_annotation     if return_annotation is inspect._empty:         for ancestor in inspect.getmro(c):             try:                 ancestor_meth = inspect.signature(getattr(ancestor, m.__name__))             except AttributeError:                 break             if ancestor_meth.return_annotation is not inspect._empty:                 return_annotation = ancestor_meth.return_annotation                 break      return sig.replace(parameters=params, return_annotation=return_annotation) In\u00a0[\u00a0]: Copied! <pre>def pascal_to_kebab(string):\n    string = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1-\\2\", string)\n    string = re.sub(\"(.)([0-9]+)\", r\"\\1-\\2\", string)\n    return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1-\\2\", string).lower()\n</pre> def pascal_to_kebab(string):     string = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1-\\2\", string)     string = re.sub(\"(.)([0-9]+)\", r\"\\1-\\2\", string)     return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1-\\2\", string).lower() In\u00a0[\u00a0]: Copied! <pre>class Linkifier:\n    def __init__(self):\n        path_index = {}\n        name_index = {}\n\n        modules = {\n            module: importlib.import_module(f\"{package}.{module}\")\n            for module in importlib.import_module(f\"{package}\").__all__\n        }\n\n        def index_module(mod_name, mod, path):\n            path = os.path.join(path, mod_name)\n            dotted_path = path.replace(\"/\", \".\")\n\n            for func_name, func in inspect.getmembers(mod, inspect.isfunction):\n                for e in (\n                    f\"{mod_name}.{func_name}\",\n                    f\"{dotted_path}.{func_name}\",\n                    f\"{func.__module__}.{func_name}\",\n                ):\n                    path_index[e] = os.path.join(path, snake_to_kebab(func_name))\n                    name_index[e] = f\"{dotted_path}.{func_name}\"\n\n            for klass_name, klass in inspect.getmembers(mod, inspect.isclass):\n                for e in (\n                    f\"{mod_name}.{klass_name}\",\n                    f\"{dotted_path}.{klass_name}\",\n                    f\"{klass.__module__}.{klass_name}\",\n                ):\n                    path_index[e] = os.path.join(path, klass_name)\n                    name_index[e] = f\"{dotted_path}.{klass_name}\"\n\n            for submod_name, submod in inspect.getmembers(mod, inspect.ismodule):\n                if submod_name not in mod.__all__ or submod_name == \"typing\":\n                    continue\n                for e in (f\"{mod_name}.{submod_name}\", f\"{dotted_path}.{submod_name}\"):\n                    path_index[e] = os.path.join(path, snake_to_kebab(submod_name))\n\n                # Recurse\n                index_module(submod_name, submod, path=path)\n\n        for mod_name, mod in modules.items():\n            index_module(mod_name, mod, path=\"\")\n\n        # Prepend {package} to each index entry\n        for k in list(path_index.keys()):\n            path_index[f\"{package}.{k}\"] = path_index[k]\n        for k in list(name_index.keys()):\n            name_index[f\"{package}.{k}\"] = name_index[k]\n\n        self.path_index = path_index\n        self.name_index = name_index\n\n    def linkify(self, text, use_fences, depth):\n        path = self.path_index.get(text)\n        name = self.name_index.get(text)\n        if path and name:\n            backwards = \"../\" * (depth + 1)\n            if use_fences:\n                return f\"[`{name}`]({backwards}{path})\"\n            return f\"[{name}]({backwards}{path})\"\n        return None\n\n    def linkify_fences(self, text, depth):\n        between_fences = re.compile(\"`[\\w\\.]+\\.\\w+`\")\n        return between_fences.sub(\n            lambda x: self.linkify(x.group().strip(\"`\"), True, depth) or x.group(), text\n        )\n\n    def linkify_dotted(self, text, depth):\n        dotted = re.compile(\"\\w+\\.[\\.\\w]+\")\n        return dotted.sub(\n            lambda x: self.linkify(x.group(), False, depth) or x.group(), text\n        )\n</pre> class Linkifier:     def __init__(self):         path_index = {}         name_index = {}          modules = {             module: importlib.import_module(f\"{package}.{module}\")             for module in importlib.import_module(f\"{package}\").__all__         }          def index_module(mod_name, mod, path):             path = os.path.join(path, mod_name)             dotted_path = path.replace(\"/\", \".\")              for func_name, func in inspect.getmembers(mod, inspect.isfunction):                 for e in (                     f\"{mod_name}.{func_name}\",                     f\"{dotted_path}.{func_name}\",                     f\"{func.__module__}.{func_name}\",                 ):                     path_index[e] = os.path.join(path, snake_to_kebab(func_name))                     name_index[e] = f\"{dotted_path}.{func_name}\"              for klass_name, klass in inspect.getmembers(mod, inspect.isclass):                 for e in (                     f\"{mod_name}.{klass_name}\",                     f\"{dotted_path}.{klass_name}\",                     f\"{klass.__module__}.{klass_name}\",                 ):                     path_index[e] = os.path.join(path, klass_name)                     name_index[e] = f\"{dotted_path}.{klass_name}\"              for submod_name, submod in inspect.getmembers(mod, inspect.ismodule):                 if submod_name not in mod.__all__ or submod_name == \"typing\":                     continue                 for e in (f\"{mod_name}.{submod_name}\", f\"{dotted_path}.{submod_name}\"):                     path_index[e] = os.path.join(path, snake_to_kebab(submod_name))                  # Recurse                 index_module(submod_name, submod, path=path)          for mod_name, mod in modules.items():             index_module(mod_name, mod, path=\"\")          # Prepend {package} to each index entry         for k in list(path_index.keys()):             path_index[f\"{package}.{k}\"] = path_index[k]         for k in list(name_index.keys()):             name_index[f\"{package}.{k}\"] = name_index[k]          self.path_index = path_index         self.name_index = name_index      def linkify(self, text, use_fences, depth):         path = self.path_index.get(text)         name = self.name_index.get(text)         if path and name:             backwards = \"../\" * (depth + 1)             if use_fences:                 return f\"[`{name}`]({backwards}{path})\"             return f\"[{name}]({backwards}{path})\"         return None      def linkify_fences(self, text, depth):         between_fences = re.compile(\"`[\\w\\.]+\\.\\w+`\")         return between_fences.sub(             lambda x: self.linkify(x.group().strip(\"`\"), True, depth) or x.group(), text         )      def linkify_dotted(self, text, depth):         dotted = re.compile(\"\\w+\\.[\\.\\w]+\")         return dotted.sub(             lambda x: self.linkify(x.group(), False, depth) or x.group(), text         ) In\u00a0[\u00a0]: Copied! <pre>def concat_lines(lines):\n    return inspect.cleandoc(\" \".join(\"\\n\\n\" if line == \"\" else line for line in lines))\n</pre> def concat_lines(lines):     return inspect.cleandoc(\" \".join(\"\\n\\n\" if line == \"\" else line for line in lines)) In\u00a0[\u00a0]: Copied! <pre>def print_docstring(obj, file, depth):\n    \"\"\"Prints a classes's docstring to a file.\"\"\"\n\n    doc = ClassDoc(obj) if inspect.isclass(obj) else FunctionDoc(obj)\n\n    printf = functools.partial(print, file=file)\n\n    printf(h1(obj.__name__))\n    printf(linkifier.linkify_fences(paragraph(concat_lines(doc[\"Summary\"])), depth))\n    printf(\n        linkifier.linkify_fences(\n            paragraph(concat_lines(doc[\"Extended Summary\"])), depth\n        )\n    )\n\n    # We infer the type annotations from the signatures, and therefore rely on the signature\n    # instead of the docstring for documenting parameters\n    try:\n        signature = inspect.signature(obj)\n    except ValueError:\n        signature = (\n            inspect.Signature()\n        )  # TODO: this is necessary for Cython classes, but it's not correct\n    params_desc = {param.name: \" \".join(param.desc) for param in doc[\"Parameters\"]}\n\n    # Parameters\n    if signature.parameters:\n        printf(h2(\"Parameters\"))\n    for param in signature.parameters.values():\n        # Name\n        printf(f\"- **{param.name}**\", end=\"\")\n        # Type annotation\n        if param.annotation is not param.empty:\n            anno = inspect.formatannotation(param.annotation)\n            anno = linkifier.linkify_dotted(anno, depth)\n            printf(f\" (*{anno}*)\", end=\"\")\n        # Default value\n        if param.default is not param.empty:\n            printf(f\" \u2013 defaults to `{param.default}`\", end=\"\")\n        printf(\"\\n\", file=file)\n        # Description\n        if param.name in params_desc:\n            desc = params_desc[param.name]\n            if desc:\n                printf(f\"    {desc}\\n\")\n    printf(\"\")\n\n    # Attributes\n    if doc[\"Attributes\"]:\n        printf(h2(\"Attributes\"))\n    for attr in doc[\"Attributes\"]:\n        # Name\n        printf(f\"- **{attr.name}**\", end=\"\")\n        # Type annotation\n        if attr.type:\n            printf(f\" (*{attr.type}*)\", end=\"\")\n        printf(\"\\n\", file=file)\n        # Description\n        desc = \" \".join(attr.desc)\n        if desc:\n            printf(f\"    {desc}\\n\")\n    printf(\"\")\n\n    # Examples\n    if doc[\"Examples\"]:\n        printf(h2(\"Examples\"))\n\n        in_code = False\n        after_space = False\n\n        for line in inspect.cleandoc(\"\\n\".join(doc[\"Examples\"])).splitlines():\n            if (\n                in_code\n                and after_space\n                and line\n                and not line.startswith(\"&gt;&gt;&gt;\")\n                and not line.startswith(\"...\")\n            ):\n                printf(\"```\\n\")\n                in_code = False\n                after_space = False\n\n            if not in_code and line.startswith(\"&gt;&gt;&gt;\"):\n                printf(\"```python\")\n                in_code = True\n\n            after_space = False\n            if not line:\n                after_space = True\n\n            printf(line)\n\n        if in_code:\n            printf(\"```\")\n    printf(\"\")\n\n    # Methods\n    if inspect.isclass(obj) and doc[\"Methods\"]:\n        printf(h2(\"Methods\"))\n        printf_indent = lambda x, **kwargs: printf(f\"    {x}\", **kwargs)  # noqa: E731\n\n        for meth in doc[\"Methods\"]:\n            printf(paragraph(f'???- note \"{meth.name}\"'))\n\n            # Parse method docstring\n            docstring = inherit_docstring(c=obj, meth=meth.name)\n            if not docstring:\n                continue\n            meth_doc = FunctionDoc(func=None, doc=docstring)\n\n            printf_indent(paragraph(\" \".join(meth_doc[\"Summary\"])))\n            if meth_doc[\"Extended Summary\"]:\n                printf_indent(paragraph(\" \".join(meth_doc[\"Extended Summary\"])))\n\n            # We infer the type annotations from the signatures, and therefore rely on the signature\n            # instead of the docstring for documenting parameters\n            signature = inherit_signature(obj, meth.name)\n            params_desc = {\n                param.name: \" \".join(param.desc) for param in doc[\"Parameters\"]\n            }\n\n            # Parameters\n            if (\n                len(signature.parameters) &gt; 1\n            ):  # signature is never empty, but self doesn't count\n                printf_indent(\"**Parameters**\\n\")\n            for param in signature.parameters.values():\n                if param.name == \"self\":\n                    continue\n                # Name\n                printf_indent(f\"- **{param.name}**\", end=\"\")\n                # Type annotation\n                if param.annotation is not param.empty:\n                    printf_indent(\n                        f\" (*{inspect.formatannotation(param.annotation)}*)\", end=\"\"\n                    )\n                # Default value\n                if param.default is not param.empty:\n                    printf_indent(f\" \u2013 defaults to `{param.default}`\", end=\"\")\n                printf_indent(\"\", file=file)\n                # Description\n                desc = params_desc.get(param.name)\n                if desc:\n                    printf_indent(f\"    {desc}\")\n            printf_indent(\"\")\n\n            # Returns\n            if meth_doc[\"Returns\"]:\n                printf_indent(\"**Returns**\\n\")\n                return_val = meth_doc[\"Returns\"][0]\n                if signature.return_annotation is not inspect._empty:\n                    if inspect.isclass(signature.return_annotation):\n                        printf_indent(\n                            f\"*{signature.return_annotation.__name__}*: \", end=\"\"\n                        )\n                    else:\n                        printf_indent(f\"*{signature.return_annotation}*: \", end=\"\")\n                printf_indent(return_val.type)\n                printf_indent(\"\")\n\n    # Notes\n    if doc[\"Notes\"]:\n        printf(h2(\"Notes\"))\n        printf(paragraph(\"\\n\".join(doc[\"Notes\"])))\n\n    # References\n    if doc[\"References\"]:\n        printf(h2(\"References\"))\n        printf(paragraph(\"\\n\".join(doc[\"References\"])))\n</pre> def print_docstring(obj, file, depth):     \"\"\"Prints a classes's docstring to a file.\"\"\"      doc = ClassDoc(obj) if inspect.isclass(obj) else FunctionDoc(obj)      printf = functools.partial(print, file=file)      printf(h1(obj.__name__))     printf(linkifier.linkify_fences(paragraph(concat_lines(doc[\"Summary\"])), depth))     printf(         linkifier.linkify_fences(             paragraph(concat_lines(doc[\"Extended Summary\"])), depth         )     )      # We infer the type annotations from the signatures, and therefore rely on the signature     # instead of the docstring for documenting parameters     try:         signature = inspect.signature(obj)     except ValueError:         signature = (             inspect.Signature()         )  # TODO: this is necessary for Cython classes, but it's not correct     params_desc = {param.name: \" \".join(param.desc) for param in doc[\"Parameters\"]}      # Parameters     if signature.parameters:         printf(h2(\"Parameters\"))     for param in signature.parameters.values():         # Name         printf(f\"- **{param.name}**\", end=\"\")         # Type annotation         if param.annotation is not param.empty:             anno = inspect.formatannotation(param.annotation)             anno = linkifier.linkify_dotted(anno, depth)             printf(f\" (*{anno}*)\", end=\"\")         # Default value         if param.default is not param.empty:             printf(f\" \u2013 defaults to `{param.default}`\", end=\"\")         printf(\"\\n\", file=file)         # Description         if param.name in params_desc:             desc = params_desc[param.name]             if desc:                 printf(f\"    {desc}\\n\")     printf(\"\")      # Attributes     if doc[\"Attributes\"]:         printf(h2(\"Attributes\"))     for attr in doc[\"Attributes\"]:         # Name         printf(f\"- **{attr.name}**\", end=\"\")         # Type annotation         if attr.type:             printf(f\" (*{attr.type}*)\", end=\"\")         printf(\"\\n\", file=file)         # Description         desc = \" \".join(attr.desc)         if desc:             printf(f\"    {desc}\\n\")     printf(\"\")      # Examples     if doc[\"Examples\"]:         printf(h2(\"Examples\"))          in_code = False         after_space = False          for line in inspect.cleandoc(\"\\n\".join(doc[\"Examples\"])).splitlines():             if (                 in_code                 and after_space                 and line                 and not line.startswith(\"&gt;&gt;&gt;\")                 and not line.startswith(\"...\")             ):                 printf(\"```\\n\")                 in_code = False                 after_space = False              if not in_code and line.startswith(\"&gt;&gt;&gt;\"):                 printf(\"```python\")                 in_code = True              after_space = False             if not line:                 after_space = True              printf(line)          if in_code:             printf(\"```\")     printf(\"\")      # Methods     if inspect.isclass(obj) and doc[\"Methods\"]:         printf(h2(\"Methods\"))         printf_indent = lambda x, **kwargs: printf(f\"    {x}\", **kwargs)  # noqa: E731          for meth in doc[\"Methods\"]:             printf(paragraph(f'???- note \"{meth.name}\"'))              # Parse method docstring             docstring = inherit_docstring(c=obj, meth=meth.name)             if not docstring:                 continue             meth_doc = FunctionDoc(func=None, doc=docstring)              printf_indent(paragraph(\" \".join(meth_doc[\"Summary\"])))             if meth_doc[\"Extended Summary\"]:                 printf_indent(paragraph(\" \".join(meth_doc[\"Extended Summary\"])))              # We infer the type annotations from the signatures, and therefore rely on the signature             # instead of the docstring for documenting parameters             signature = inherit_signature(obj, meth.name)             params_desc = {                 param.name: \" \".join(param.desc) for param in doc[\"Parameters\"]             }              # Parameters             if (                 len(signature.parameters) &gt; 1             ):  # signature is never empty, but self doesn't count                 printf_indent(\"**Parameters**\\n\")             for param in signature.parameters.values():                 if param.name == \"self\":                     continue                 # Name                 printf_indent(f\"- **{param.name}**\", end=\"\")                 # Type annotation                 if param.annotation is not param.empty:                     printf_indent(                         f\" (*{inspect.formatannotation(param.annotation)}*)\", end=\"\"                     )                 # Default value                 if param.default is not param.empty:                     printf_indent(f\" \u2013 defaults to `{param.default}`\", end=\"\")                 printf_indent(\"\", file=file)                 # Description                 desc = params_desc.get(param.name)                 if desc:                     printf_indent(f\"    {desc}\")             printf_indent(\"\")              # Returns             if meth_doc[\"Returns\"]:                 printf_indent(\"**Returns**\\n\")                 return_val = meth_doc[\"Returns\"][0]                 if signature.return_annotation is not inspect._empty:                     if inspect.isclass(signature.return_annotation):                         printf_indent(                             f\"*{signature.return_annotation.__name__}*: \", end=\"\"                         )                     else:                         printf_indent(f\"*{signature.return_annotation}*: \", end=\"\")                 printf_indent(return_val.type)                 printf_indent(\"\")      # Notes     if doc[\"Notes\"]:         printf(h2(\"Notes\"))         printf(paragraph(\"\\n\".join(doc[\"Notes\"])))      # References     if doc[\"References\"]:         printf(h2(\"References\"))         printf(paragraph(\"\\n\".join(doc[\"References\"]))) In\u00a0[\u00a0]: Copied! <pre>def print_module(mod, path, overview, is_submodule=False):\n    mod_name = mod.__name__.split(\".\")[-1]\n\n    # Create a directory for the module\n    mod_slug = snake_to_kebab(mod_name)\n    mod_path = path.joinpath(mod_slug)\n    mod_short_path = str(mod_path).replace(\"docs/api/\", \"\")\n    os.makedirs(mod_path, exist_ok=True)\n    with open(mod_path.joinpath(\".pages\"), \"w\") as f:\n        f.write(f\"title: {mod_name}\")\n\n    # Add the module to the overview\n    if is_submodule:\n        print(h3(mod_name), file=overview)\n    else:\n        print(h2(mod_name), file=overview)\n    if mod.__doc__:\n        print(paragraph(mod.__doc__), file=overview)\n\n    # Extract all public classes and functions\n    ispublic = lambda x: x.__name__ in mod.__all__ and not x.__name__.startswith(\"_\")  # noqa: E731\n    classes = inspect.getmembers(mod, lambda x: inspect.isclass(x) and ispublic(x))\n    funcs = inspect.getmembers(mod, lambda x: inspect.isfunction(x) and ispublic(x))\n\n    # Classes\n\n    if classes and funcs:\n        print(\"\\n**Classes**\\n\", file=overview)\n\n    for _, c in classes:\n        print(f\"{mod_name}.{c.__name__}\")\n\n        # Add the class to the overview\n        slug = snake_to_kebab(c.__name__)\n        print(\n            li(link(c.__name__, f\"../{mod_short_path}/{slug}\")), end=\"\", file=overview\n        )\n\n        # Write down the class' docstring\n        with open(mod_path.joinpath(slug).with_suffix(\".md\"), \"w\") as file:\n            print_docstring(obj=c, file=file, depth=mod_short_path.count(\"/\") + 1)\n\n    # Functions\n\n    if classes and funcs:\n        print(\"\\n**Functions**\\n\", file=overview)\n\n    for _, f in funcs:\n        print(f\"{mod_name}.{f.__name__}\")\n\n        # Add the function to the overview\n        slug = snake_to_kebab(f.__name__)\n        print(\n            li(link(f.__name__, f\"../{mod_short_path}/{slug}\")), end=\"\", file=overview\n        )\n\n        # Write down the function' docstring\n        with open(mod_path.joinpath(slug).with_suffix(\".md\"), \"w\") as file:\n            print_docstring(obj=f, file=file, depth=mod_short_path.count(\".\") + 1)\n\n    # Sub-modules\n    for name, submod in inspect.getmembers(mod, inspect.ismodule):\n        # We only want to go through the public submodules, such as optim.schedulers\n        if (\n            name in (\"tags\", \"typing\", \"inspect\", \"skmultiflow_utils\")\n            or name not in mod.__all__\n            or name.startswith(\"_\")\n        ):\n            continue\n        print_module(mod=submod, path=mod_path, overview=overview, is_submodule=True)\n\n    print(\"\", file=overview)\n</pre> def print_module(mod, path, overview, is_submodule=False):     mod_name = mod.__name__.split(\".\")[-1]      # Create a directory for the module     mod_slug = snake_to_kebab(mod_name)     mod_path = path.joinpath(mod_slug)     mod_short_path = str(mod_path).replace(\"docs/api/\", \"\")     os.makedirs(mod_path, exist_ok=True)     with open(mod_path.joinpath(\".pages\"), \"w\") as f:         f.write(f\"title: {mod_name}\")      # Add the module to the overview     if is_submodule:         print(h3(mod_name), file=overview)     else:         print(h2(mod_name), file=overview)     if mod.__doc__:         print(paragraph(mod.__doc__), file=overview)      # Extract all public classes and functions     ispublic = lambda x: x.__name__ in mod.__all__ and not x.__name__.startswith(\"_\")  # noqa: E731     classes = inspect.getmembers(mod, lambda x: inspect.isclass(x) and ispublic(x))     funcs = inspect.getmembers(mod, lambda x: inspect.isfunction(x) and ispublic(x))      # Classes      if classes and funcs:         print(\"\\n**Classes**\\n\", file=overview)      for _, c in classes:         print(f\"{mod_name}.{c.__name__}\")          # Add the class to the overview         slug = snake_to_kebab(c.__name__)         print(             li(link(c.__name__, f\"../{mod_short_path}/{slug}\")), end=\"\", file=overview         )          # Write down the class' docstring         with open(mod_path.joinpath(slug).with_suffix(\".md\"), \"w\") as file:             print_docstring(obj=c, file=file, depth=mod_short_path.count(\"/\") + 1)      # Functions      if classes and funcs:         print(\"\\n**Functions**\\n\", file=overview)      for _, f in funcs:         print(f\"{mod_name}.{f.__name__}\")          # Add the function to the overview         slug = snake_to_kebab(f.__name__)         print(             li(link(f.__name__, f\"../{mod_short_path}/{slug}\")), end=\"\", file=overview         )          # Write down the function' docstring         with open(mod_path.joinpath(slug).with_suffix(\".md\"), \"w\") as file:             print_docstring(obj=f, file=file, depth=mod_short_path.count(\".\") + 1)      # Sub-modules     for name, submod in inspect.getmembers(mod, inspect.ismodule):         # We only want to go through the public submodules, such as optim.schedulers         if (             name in (\"tags\", \"typing\", \"inspect\", \"skmultiflow_utils\")             or name not in mod.__all__             or name.startswith(\"_\")         ):             continue         print_module(mod=submod, path=mod_path, overview=overview, is_submodule=True)      print(\"\", file=overview) In\u00a0[\u00a0]: Copied! <pre>if __name__ == \"__main__\":\n    api_path = pathlib.Path(\"docs/api\")\n\n    # Create a directory for the API reference\n    shutil.rmtree(api_path, ignore_errors=True)\n    os.makedirs(api_path, exist_ok=True)\n    with open(api_path.joinpath(\".pages\"), \"w\") as f:\n        f.write(\"title: API reference\\narrange:\\n  - overview.md\\n  - ...\\n\")\n\n    overview = open(api_path.joinpath(\"overview.md\"), \"w\")\n    print(h1(\"Overview\"), file=overview)\n\n    linkifier = Linkifier()\n\n    for mod_name, mod in inspect.getmembers(\n        importlib.import_module(f\"{package}\"), inspect.ismodule\n    ):\n        if mod_name.startswith(\"_\"):\n            continue\n        print(mod_name)\n        print_module(mod, path=api_path, overview=overview)\n</pre> if __name__ == \"__main__\":     api_path = pathlib.Path(\"docs/api\")      # Create a directory for the API reference     shutil.rmtree(api_path, ignore_errors=True)     os.makedirs(api_path, exist_ok=True)     with open(api_path.joinpath(\".pages\"), \"w\") as f:         f.write(\"title: API reference\\narrange:\\n  - overview.md\\n  - ...\\n\")      overview = open(api_path.joinpath(\"overview.md\"), \"w\")     print(h1(\"Overview\"), file=overview)      linkifier = Linkifier()      for mod_name, mod in inspect.getmembers(         importlib.import_module(f\"{package}\"), inspect.ismodule     ):         if mod_name.startswith(\"_\"):             continue         print(mod_name)         print_module(mod, path=api_path, overview=overview)"}]}